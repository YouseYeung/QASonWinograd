\documentclass{llncs}

\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{longtable}

\allowdisplaybreaks[4]

\newcommand\etc{{\it et al.}}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmicreturn}{\textbf{Initialize:}}

\begin{document}

\title{An Improved Multi-agent Epistemic Planner\\ via Higher-order Belief Change \\based on Heuristic Search}
%\author{Zhongbin Wu \and Yongmei Liu
%}
%\institute{
%Sun Yat-sen University \email{wuzhb3@mail2.sysu.edu.cn}
%\and Sun Yat-sen University \email{ymliu@mail.sysu.edu.cn}
%}

\maketitle

\begin{abstract}
  Recently, multi-agent epistemic planning has drawn attention from both dynamic logic and planning communities. Existing implementations are based on compilation into classical planning, which suffers from limitations such as incapability to handle disjunctive beliefs, or higher-order belief change and forward state space search, as exploited by the planner MEPK. However, MEPK does not scale well.In this paper, we propose two improvements for MEPK. Firstly, we exploit another normal form for multi-agent KD45, which is more space efficient than the normal form used by MEPK, and propose efficient reasoning, revision, and update algorithms for it. Secondly, we propose a heuristic function for multi-agent epistemic planning, and apply heuristic search algorithm AO* with cycle checking and two heuristic pruning strategies. We implemented a multi-agent epistemic planner called MEPL. Our experimental results show that MEPL outperforms MEPK in most planning instances, and solves a number of instances which MEPK cannot solve.


  \keywords{Modal logics, multi-agent epistemic planning, heuristic search}

\end{abstract}

\section{Introduction}

Many intelligent tasks involve the collaboration and communication among multiple agents, raising the need of reasoning about knowledge and beliefs, and their change. For example, reasoning is performed before taking an action to check whether its precondition has been satisfied. Belief change is incurred because the performance of actions may change not only the environment but also the beliefs of agents. Reasoning about high-order knowledge and belief and their change is also needed in some cases. For example, an agent may wish that she knows an information and the other agents know that she knows the information.

In recent years, multi-agent epistemic planning has drawn great attention from both dynamic logic and planning communities. On the theory side, Bolander and Andersen \cite{bolander2011epistemic} formalized multi-agent epistemic planning based on dynamic epistemic logic \cite{van2007dynamic} and showed that it is undecidable in general. On the implementation side, Kominis and Geffner \cite{kominis2015beliefs} and Muise \etc\ \cite{muise2015planning} showed how to solve restricted versions of multi-agent epistemic planning problems by resorting to classical planning. However, this approach suffers from many limitations, like generating only linear plans, restriction to public actions, and incapability to handle disjunctive beliefs.

Very recently, Huang \etc\ \cite{Liu2017A} proposed a general representation framework for multi-agent epistemic planning, where the initial KB and the goal, the preconditions and effects of actions can be
arbitrary multi-agent epistemic formulas, progression of KBs wrt actions is achieved through the operation of belief revision or update, and the solution is an action tree branching on sensing results.
To support efficient reasoning and progression, they resorted to a
normal form for multi-agent KD45 logic called alternating cover disjunctive formulas (ACDFs). Using forward state space search, they implemented a multi-agent epistemic planner MEPK. However, MEPK does not scale well.


In the field of planning, heuristic search has shown large potential and has been widely applied. Bonnet and Geffner \cite{bonnet1998hsp} proposed the delete relaxation heuristic for classical planning, which was further developed in the FF planning system \cite{Hoffman2011Fast}. Besides, Mattm{\"{u}}ller \etc\ \cite{Mattm2010Pattern} explored pattern database heuristics for fully observable non-deterministic (FOND) planning, and applied the heuristic search algorithm LAO* \cite{Hansen2001LAO}.
 Winterer \etc\ \cite{Winterer2016Structural} generalized
structural symmetries and
symmetry reduction to FOND planning with LAO*.

In this paper, we propose two improvements for the multi-agent epistemic planner MEPK. Firstly, we exploit alternating disjunctive normal form for multi-agent KD45, which is more space efficient than ACDFs and also saves time in compilation, and propose efficient reasoning, revision, and update algorithms for it. Secondly, we propose a heuristic function for multi-agent epistemic planning, and apply heuristic research AO* with cycle checking and two heuristic pruning strategies.
Finally, based on our theoretic work, we implemented a multi-agent epistemic planner called MEPL. Our experimental results show that MEPL outperforms MEPK in most planning instances, and solves a number of instances which MEPK cannot solve.


\section{Preliminaries}
%In this section, we will introduce the background work of our paper: the multi-agent modal logic KD45$_n$, belief revision and update, and the modeling framework proposed in \cite{Liu2017A}.
\subsection{Multi-agent Modal Logic KD45$_n$}
Throughout our paper, we let $\mathcal{A}$ denote a finite set of agents, and $\mathcal{P}$ a finite set of atoms. We use $\phi, \psi, \varphi, \delta$ to represent a formula, $\Phi, \Psi$ to represent the set of formulas, and $\top$ and $\bot$ to represent $True$ and $False$ respectively.
Besides, we let $\bigvee\Phi$ (resp. $\bigwedge\Phi$) denote the disjunction (resp. conjunction) of members in $\Phi$.\vspace{0.05in}\\
\textbf{Definition 1.} \textit{The language $\mathcal{L}_{\mathcal{K}\mathcal{C}}$ of multi-agent modal logic with common knowledge is generated by the BNF:\\
\centerline{$\varphi$ $::=p$ $|$ $\lnot\phi$ $|$ $(\phi\land\psi)$ $|$ $K_a\phi$ $|$ $C\phi$ ,}
where $a\in\mathcal{A}, p\in\mathcal{P}, \phi,\psi\in\mathcal{L}_{\mathcal{K}\mathcal{C}}$. We use $\mathcal{L}_\mathcal{K}$ for the language without $C$ operator, and $\mathcal{L}_0$ for propositional language.} \vspace{0.05in}\\
Intuitively, $K_a\phi$ means agent $a$ knows $\phi$ and $C\phi$ means commonly knowing $\phi$. Similar to \cite{Liu2017A}, we only discuss the case of propositional common knowledge, i.e., $C\phi$ where $\phi\in\mathcal{L}_0$, and we also call it a constraint.\vspace{0.05in}\\
\textbf{Definition 2.} \textit{A frame is a pair $(W, R)$, where $W$ is a non-empty set of possible worlds; for each agent $a\in\mathcal{A}$, $R_a$ is a binary relation on $W$, called the accessibility relation for agent $a$ and $R=\bigcup_{a\in\mathcal{A}}R_a$.}\vspace{0.05in}\\
We say that an accessibility relation $R_a$ is serial if for any $w\in W$ we have $w'\in W$ s.t. $(w, w')\in R_a$; $R_a$ is transitive if $\forall w,u,v \in W, (w,u)\in R_a$ and $(u,v)\in R_a$ implies $(w,v)\in R_a$; $R_a$ is Euclidean if $\forall w,w_1,w_2 \in W, (w,w_1)\in R_a$ and $(w,w_2)\in R_a$ implies $(w_1,w_2)\in R_a$. A KD45$_n$ frame is a frame whose accessibility relations are serial, transitive and Euclidean.\vspace{0.05in}\\
\textbf{Definition 3.} \textit{A Kripke model is a triple $M=(W,R,V)$, where $(W,R)$ is a frame and $V: W\rightarrow 2^{\mathcal{P}}$ is a valuation map that maps each $w\in W$ to a subset of $\mathcal{P}$. A pointed Kripke model is a pair $(M, w)$, where $M$ is a Kripke model and $w$ is a world of $M$, which is called the actual world.}\vspace{0.05in}\\
\textbf{Definition 4.} \textit{Let $s = (M, w)$ be an pointed Kripke model where $M=(W,R,V)$. We interpret formulas in $\mathcal{L}_{\mathcal{K}\mathcal{C}}$ inductively:\\
\hspace*{0.1in}$\bullet$ $M, w\models p$ iff $p\in V(w)$;\\
\hspace*{0.1in}$\bullet$ $M, w\models \lnot\phi$ iff $M, w\not\models\phi$;\\
\hspace*{0.1in}$\bullet$ $M, w\models\phi\land\psi$ iff $M, w\models\phi$ and $M, w\models\psi$;\\
\hspace*{0.1in}$\bullet$ $M, w\models K_a\phi$ iff for all $v$ s.t. $(w,v)\in R_a$, $M,v\models\phi$;\\
\hspace*{0.1in}$\bullet$ $M, w\models C\phi$ iff for all $v$ s.t. $(w,v)\in R_\mathcal{T}$, $M, v\models\phi$, where $R_\mathcal{T}$ is the transi-\\ \hspace*{0.1in}\hspace{0.1in}tive closure of the union of $R$.}\vspace{0.05in}\\
We say $\phi$ is satisfiable if there is a pointed KD45$_n$ model s.t. $M, w\models\phi$. We say $\phi$ entails $\psi$, written $\phi\models\psi$, if for all model $(M, w)$, $M, w\models\phi$ implies $M,w\models\psi$; and $\phi$ and $\psi$ are equivalent, written $\phi\Leftrightarrow\psi$, if $\phi\models\psi$ and $\psi\models\phi$. Similarly, we say $\phi$ is satisfiable under constraint $\gamma$ if there is a pointed KD45$_n$ model s.t. $M, w\models\phi\land\gamma\land C\gamma$. We say $\phi$ entails $\psi$ under constraint $\gamma$, written $\phi\models_\gamma\psi$, if for all model $(M, w)$, $M, w\models\phi\land\gamma\land C\gamma$ implies $M,w\models\psi\land\gamma\land C\gamma$; and $\phi$ and $\psi$ is equivalent under constraint $\gamma$, written $\phi\Leftrightarrow_\gamma\psi$, if $\phi\models_\gamma\psi$ and $\psi\models_\gamma\phi$.

Now we introduce the normal form used in our paper. We let $L_a\phi$ denote $\lnot K_a\lnot\phi$, and $L_a\Phi$ denote the conjunction of $L_a\phi$, where $\phi\in\Phi$.\vspace{0.05in}\\
\textbf{Definition 5.} \textit{We define the set of $\mathcal{L}_{K}$ normal terms, called KTerms, as follows:\\
    \hspace*{0.1in}$\bullet$ A propositional term, i.e., a conjunction of literals, is a normal term;\\
    \hspace*{0.1in}$\bullet$ A formula of the form $\phi_0\land\bigwedge_{a\in\mathcal{A}}(K_a\phi_a\land L_a\Psi_a)$ is a normal term, where\\
    \hspace*{0.1in}\hspace{0.1in} $-$ $\phi_0$ is a propositional term;\\
    \hspace*{0.1in}\hspace{0.1in} $-$ $\phi_a$ is a disjunction of $\mathcal{L}_{K}$ normal terms; \\
    \hspace*{0.1in}\hspace{0.1in} $-$ $\Psi_a$ is a set of $\mathcal{L}_{K}$ normal terms.} \vspace{0.05in}\\
We say that a KTerm has the alternating property if modal operators of an agent does not occur directly inside modal operators of the same agent. For example, $K_a(K_b(p))$ has the alternating property while $K_a(K_a(p))$ does not. %Next, we introduce the notion ADNF used to represent the KB in our paper.
\vspace{0.05in}\\
\textbf{Definition 6.} \textit{A disjunction of alternating KTerms is called an alternating DNF (ADNF).}

It is easy to prove the following:
\vspace{0.05in}\\
\textbf{Proposition 1.}
\textit{In KD45$_n$, every formula in $\mathcal{L}_\mathcal{K}$ can be converted to an equivalent ADNF.}\vspace{0.05in}\\
\textbf{Proposition 2.} \textit{Let $\delta=\phi_0\land\bigwedge_{a\in\mathcal{A}}(K_a\phi_a\land L_a\Psi_a)$,  $\delta'=\phi_0'\land\bigwedge_{a\in\mathcal{A}}(K_a\phi_a'\land L_a\Psi_a')$ be two alternating KTerms and $\gamma$ be a constraint. $\delta\models_\gamma\delta'$ iff the following hold:\\
\hspace*{0.1in}$\bullet$ $\phi_0\land\gamma\models\phi_0'$ propositionally;\\
\hspace*{0.1in}$\bullet$ For each $a\in\mathcal{A}$, $\phi_a\models_\gamma\phi_a'$;\\
\hspace*{0.1in}$\bullet$ For each $a\in\mathcal{A}$, for every $\psi_a'\in\Psi_a'$ there is a $\psi_a\in\Psi_a$ s.t. $\phi_a\land\psi_a\models\psi_a'$.}\vspace{0.05in}
\subsection{Belief Revision and Update}
Revision and update are two kinds of methods for belief change with new belief. Revision concerns belief change due to the partial or incorrect information while update concerns belief change caused by taking actions. Many guidelines about revision and update have been proposed which include belief revision in \cite{alchourron1985logic}, belief update in \cite{mendelzon1991difference} and iterated belief revision in \cite{darwiche1997logic}. We use $\circ$ to denote revision operator and $\diamond$ to denote update operator.  \cite{mendelzon1991difference} has introduced the main difference between revision and update in a model-theoretic way: let $\phi$ and $\psi$ be two formulas, $\phi\circ\psi$ selects from $\psi$ the models that are closest to that in $\phi$, and $\phi\diamond\psi$ selects, for each model $M$ of $\phi$, the set of models from $\psi$ that are closest to $M$, intuitively. As easy properties, we can get:\\
\hspace*{0.1in}$\bullet$ Satisfiability Property of revision: if $\phi\land\psi$ is satisfiable, then $\phi\circ\psi\Leftrightarrow\phi\land\psi$.\\
\hspace*{0.1in}$\bullet$ Distribution Property of update: $(\phi_1\lor\phi_2)\diamond\psi\Leftrightarrow(\phi_1\diamond\psi)\lor(\phi_2\diamond\psi)$.

\subsection{Modeling Framework}
 We now introduce the modeling framework for multi-agent epistemic planning from \cite{Liu2017A}.
 %We firstly define multi-agent epistemic planning (MEP) problems, and then two kinds of actions and their progression, and finally the solution of MEP problem.
 \vspace{0.05in}\\
\textbf{Definition 7.} \textit{A multi-agent epistemic planning (MEP) problem $\mathcal{Q}$ is a tuple $\langle\mathcal{A}, \mathcal{P}, \mathcal{D}, \mathcal{S}, \mathcal{I}, \mathcal{G}, \gamma\rangle$, where $\mathcal{A}$ is the set of agents, $\mathcal{P}$ is the set of atoms, $\mathcal{D}$ is the set of deterministic actions, $\mathcal{S}$ is the set of sensing actions, $\mathcal{I}\in\mathcal{L}_\mathcal{K}$ is the initial state, $\mathcal{G}\in\mathcal{L}_\mathcal{K}$ is the goal and $\gamma\in\mathcal{L}_0$ is the constraint.}\vspace{0.05in}\\
\textbf{Definition 8.} \textit{A deterministic action is a pair $\langle pre, effs\rangle$, where $pre\in\mathcal{L}_\mathcal{K}$ is the precondition, and $effs$ is a set of conditional effects, each of which is a pair $\langle con, cef\rangle$, where $con, cef\in\mathcal{L}_\mathcal{K}$ are the condition and conditional effect.}\vspace{0.05in}\\
\textbf{Definition 9.} \textit{A sensing action is a triple $\langle pre, pos, neg \rangle$, where $pre, pos, neg\in\mathcal{L}_\mathcal{K}$ are the precondition, positive result and negative result, respectively.}\vspace{0.05in}\\
An action $a$ is executable on KB $\phi$ under constraint $\gamma$ if $\phi\models_\gamma pre(a)$. Assume that $\phi\models_\gamma pre(a)$, the progression of $\phi$ wrt action $a$ is defined by using update operator under constraint $\gamma$, written $\diamond_\gamma$,  for deterministic action and revision operator under constraint $\gamma$, written $\circ_\gamma$, for sensing action.\vspace{0.05in}\\
\textbf{Definition 10.} \textit{Let $\phi\in\mathcal{L}_\mathcal{K}$, and $a_d$ a deterministic action with $effs(a_d)=\{\langle con_1, cef_1\rangle,...,\langle con_n, cef_n\rangle\}$. Let $\{\langle c_1, e_1 \rangle,...,\langle c_k, e_k\rangle\}\subseteq eff(a_d)$ s.t. $\phi\models_\gamma c_i$, for $1\leq i \leq k$. The progression of $\phi$ wrt $a_d$ under constraint $\gamma$, written $prog(\phi, a_d)$, is defined as $prog(\phi, a_d)=((\phi\diamond_\gamma e_1)...)\diamond_\gamma e_k$.}\vspace{0.05in}\\
\textbf{Definition 11.} \textit{Let $\phi\in\mathcal{L}_\mathcal{K}$, and $a_s = \{pre, pos, neg\}$ a sensing action. The progression of $\phi$ wrt $a_s$ under constraint $\gamma$, written $prog(\phi, a_s)$, is a pair $\langle \phi^+, \phi^-\rangle$, where $\phi^+=\phi\circ_\gamma pos(a_s)$ and $\phi^-=\phi\circ_\gamma neg(a_s)$.}\vspace{0.05in}\\
A solution of a multi-agent epistemic planning problem is an action tree branching on sensing actions. We use $\epsilon$ to denote an empty action tree.\vspace{0.05in}\\
\textbf{Definition 12.} \textit{Let $\mathcal{Q}=\langle\mathcal{A}, \mathcal{P}, \mathcal{D}, \mathcal{S}, \mathcal{I}, \mathcal{G}, \gamma\rangle$ be a MEP problem. The set $\mathcal{T}$ of action tree is defined recursively:\\
\hspace*{0.1in}$\bullet$ $\epsilon$ is in $\mathcal{T}$;\\
\hspace*{0.1in}$\bullet$ If $a_d\in\mathcal{D}$ and $T\in\mathcal{T}$, then $a_d;T$ is in $\mathcal{T}$;\\
\hspace*{0.1in}$\bullet$ If $a_s\in\mathcal{S}$ and $T^+,T^-\in\mathcal{T}$, then $a_s;(T^+|T^-)$ is in $\mathcal{T}$.}\vspace{0.05in}\\
\textbf{Definition 13.} \textit{Let $\phi\in\mathcal{L}_\mathcal{K}$, $T$ an action tree. The progression of $\phi$ wrt $T$, written $prog(\phi, T)$ is defined recursively:\\
\hspace*{0.1in}$\bullet$ $prog(\phi,\epsilon)=\{\phi\}$;\\
\hspace*{0.1in}$\bullet$ If $\phi\models_\gamma pre(a_d)$, $prog(\phi, a_d;T')=prog(prog(\phi, a_d), T')$;\\
\hspace*{0.1in}$\bullet$ If $\phi\models_\gamma pre(a_s)$, $prog(\phi, a_s;(T^+|T^-))=prog(\phi^+, T^+)\bigcup prog(\phi^-, T^-)$, where\\
\hspace*{0.1in}\hspace{0.1in}$prog(\phi, a_s)=\langle \phi^+,\phi^-\rangle$;\\
\hspace*{0.1in}$\bullet$ Otherwise, $prog(\phi, T)$ is undefined.}\vspace{0.05in}\\
\textbf{Definition 14.} \textit{Let $\mathcal{Q}=\langle\mathcal{A}, \mathcal{P}, \mathcal{D}, \mathcal{S}, \mathcal{I}, \mathcal{G}, \gamma\rangle$ be a MEP problem, an action tree $T$ is a solution for $\mathcal{Q}$ if $prog(\mathcal{I}, T)$ is defined, and $\forall \phi\in prog(\mathcal{I}, T)$, $\phi\models_\gamma\mathcal{G}$.}
\section{Reasoning and Progression}
In this section, we will introduce the basic algorithms for ADNFs: satisfiability, strong entailment and strong equivalence, revision and update. In our planner, in order to support efficient reasoning and knowledge progression, we use DNFs to represent the constraint and ADNFs for other formulas, including the initial state, the goal, the condition and the effect of actions.
\subsection{Satisfiability}
To support efficient reasoning, our planner firstly transforms $pre(a)$ into negation form. Next, we will introduce the reasoning algorithm for ADNFs.\vspace{0.05in}\\
\textbf{Proposition 3.} \textit{An alternating KTerm $\phi=\phi_0\land\bigwedge_{a\in\mathcal{A}}(K_a\phi_a\land L_a\Psi_a)$ is satisfiable wrt constraint $\gamma$ iff the following hold:\\
\hspace*{0.1in} $1$. $\phi_0\land\gamma$ is propositionally satisfiable;\\
\hspace*{0.1in} $2$. For each $a \in \mathcal{A}$, $\phi_a$ is satisfiable wrt $\gamma$;\\
\hspace*{0.1in} $3$. For each $a \in \mathcal{A}$, for each $\psi_a\in\Psi_a$, $\phi_a\land\psi_a$ is satisfiable wrt $\gamma$.}\vspace{0.05in}\\
\textbf{Proposition 4.} \textit{Let $\phi$ and $\phi'$ be two ADNFs. \\
\hspace*{0.1in}$\bullet$ When $\phi$ and $\phi'$ are propositional terms, $\phi\land\phi'$ is satisfiable wrt constraint \\
\hspace*{0.1in}\hspace{0.1in} $\gamma$ iff $\phi\land\phi'\land\gamma$ doesn't have complementary literals; \\
\hspace*{0.1in}$\bullet$ When $\phi=\bigvee\Psi$ and $\phi'=\bigvee\Psi'$, $\phi\land\phi'$ is satisfiable wrt constraint $\gamma$ iff there\\
\hspace*{0.1in}\hspace{0.1in} exist $\psi\in\Psi$ and $\psi'\in\Psi'$ s.t. $\psi\land\psi'$ is satisfiable wrt constraint $\gamma$;\\
\hspace*{0.1in}$\bullet$ When $\phi=\phi_0\land\bigwedge_{a\in\mathcal{B}}(K_a\phi_a\land L_a\Psi_a)$ and $\phi'=\phi_0'\land\bigwedge_{a\in\mathcal{B}'}(K_a\phi_a'\land L_a\Psi_a')$, \\
\hspace*{0.1in}\hspace{0.1in} where $\mathcal{B},\mathcal{B}'\subseteq\mathcal{A}$, $\phi\land\phi'$ is satisfiable wrt constraint $\gamma$ iff the following hold:\\
\hspace*{0.1in}\quad $-$ $\phi$, $\phi'$ and $\phi_0\land\phi_0'$ are satisfiable wrt constraint $\gamma$;\\
\hspace*{0.1in}\quad $-$ For each $a\in\mathcal{B}\cap\mathcal{B}'$, $\phi_a\land\phi_a'$ is satisfiable wrt $\gamma$;\\
\hspace*{0.1in}\quad $-$ For each $a\in\mathcal{B}\cap\mathcal{B}'$, for each $\psi\in\Psi_a$, $\phi_a\land\phi_a'\land\psi$ is satisfiable wrt $\gamma$;\\
\hspace*{0.1in}\quad $-$ For each $a\in\mathcal{B}\cap\mathcal{B}'$, for each $\psi'\in\Psi_a'$, $\phi_a\land\phi_a'\land\psi'$ is satisfiable wrt $\gamma$.}\vspace{0.05in}\\
Now we can solve the reasoning problem by solving an equivalent satisfiability problem, i.e., $\phi\models_\gamma\phi'$ iff $\phi\land\lnot\phi'$ is not satisfiable wrt $\gamma$.
\subsection{Strong Entailment and Strong Equivalence}
Our planner searches for solution through the space of KBs, and performs cycle checking during searching. Thus, we need an efficient algorithm for checking equivalence relation. In the last section, we have defined the algorithm for knowledge reasoning. However, except for formulas that can be compiled into the negation ADNFs during preprocess, it's not tolerable to transform a new formula because the formula may become too long according to the distributive law. In this section, we will introduce a stronger notion of equivalence.\vspace{0.05in}\\
\textbf{Definition 15.} \textit{Let $\phi$ and $\phi'$ be two ADNFs and $\gamma$ be a constraint. $\phi$ strongly entail $\phi'$ wrt $\gamma$, written $\phi\mapsto_\gamma\phi'$, is defined recursively:\\
\hspace*{0.1in}$\bullet$ When $\phi$ and $\phi'$ are propositional formulas, $\phi\mapsto_\gamma\phi'$ if $\phi\land\gamma\models\phi'$;\\
\hspace*{0.1in}$\bullet$ When $\phi=\bigvee\Psi$ and $\phi'=\bigvee\Psi'$, $\phi\mapsto_\gamma\phi'$ if $\forall\psi\in\Psi,\exists\psi'\in\Psi'$ s.t. $\psi\mapsto_\gamma\psi'$;\\
\hspace*{0.1in}$\bullet$ When $\phi=\phi_0\land\bigwedge_{a\in\mathcal{B}}(K_a\phi_a\land L_a\Psi_a)$ and $\phi'=\phi_0'\land\bigwedge_{a\in\mathcal{B}'}(K_a\phi_a'\land L_a\Psi_a')$, \\
\hspace*{0.1in}\hspace{0.1in} where $\mathcal{B},\mathcal{B}'\subseteq\mathcal{A}$. $\phi\mapsto_\gamma\phi'$ if the following hold:\\
\hspace*{0.1in}\quad $-$ $\mathcal{B}'\subseteq\mathcal{B}$ and $\phi_0\mapsto_\gamma\phi_0'$;\\
\hspace*{0.1in}\quad $-$ For each $a\in\mathcal{B}'$, $\phi_a\mapsto_\gamma\phi_a'$;\\
\hspace*{0.1in}\quad $-$ For each $a\in\mathcal{B}'$, for all $\psi'\in\Psi_a'$ there exists $\psi\in\Psi_a$ s.t. $\phi_a\land\psi\mapsto_\gamma\psi'$.}\vspace{0.05in}\\
%Obviously, the strong entailment relation can be checked in polynomial time.
By Proposition 2 we can easily get:\vspace{0.05in}\\
\textbf{Proposition 5.} \textit{Let $\phi$ and $\phi'$ be two ADNFs, and $\gamma$ be a constraint. $\phi\mapsto_\gamma\phi'$ implies $\phi\models_\gamma\phi'$.}\vspace{0.05in}\\
We say that two ADNFs $\phi$ and $\phi'$ are strongly equivalent under $\gamma$, written $\phi\leftrightarrow_\gamma\phi'$, if both $\phi\mapsto_\gamma\phi'$ and $\phi'\mapsto_\gamma\phi$.
\subsection{Revision and Update}
In this section, we will introduce the revision and update algorithms. The basic idea is that we revise or update a higher order epistemic formula by reducing it to that of lower order, applying the revision or update recursively, and finally resorting it to the progression of propositional formulas as basis. We will also show that our algorithm satisfies the basic corollaries mentioned above. We begin with some notions. Let $\Phi$ and $\Phi'$ be two sets of formulas and $\gamma$ be a constraint:\\
\hspace*{0.1in}$\bullet$ $\Phi*_\gamma\Phi'$=\\
\hspace*{0.1in}\quad $-$ $\{(\phi,\phi')|\phi\in\Phi,\phi'\in\Phi', \phi\land\phi'$ is satisfiable wrt $\gamma\}$ , if there exist $\phi\in\Phi$\\
\hspace*{0.1in}\quad\quad and $\phi'\in\Phi'$ s.t. $\phi\land\phi'$ is satisfiable wrt $\gamma$;\\
\hspace*{0.1in}\quad $-$ $\{(\phi,\phi')|\phi\in\Phi,\phi'\in\Phi'\}$, otherwise.\\
\hspace*{0.1in}$\bullet$ $\max{(\Phi)}=\Phi-\{\phi$ $|$ $\phi\in\Phi,$ and there exists $\phi'\in\Phi$ s.t. $\phi'\models_\gamma\phi\}$.\\
Intuitively, $\Phi*\Phi'$ means that we will always restrict our attention to those pairs that are consistent whenever possible. $\max{(\Phi)}$ is the set of the maximal elements of $\Phi$, i.e., elements which are not entailed by some other elements of $\Phi$.
For example, we will store the formula $L_a\{p\land q\}$ rather than $L_a\{p, p\land q\}$.\vspace{0.05in}\\
\textbf{Definition 16.} \textit{Let $\phi$ and $\phi'$ be two ADNFs and $\gamma$ be a constraint. The revision of $\phi$ with $\phi'$ under $\gamma$, written $\phi\circ_\gamma\phi'$, is defined recursively:\\
\hspace*{0.1in} $1$. When $\phi$ and $\phi'$ are propositional formulas, $\phi\circ_\gamma\phi'=\phi\circ_s(\phi'\land\gamma)$, where $\circ_s$ \\
\hspace*{0.1in}\hspace{0.15in} is the Satoh's revision operator\cite{satoh1988nonmonotonic};\\
\hspace*{0.1in} $2$. When $\phi=\bigvee\Psi$ and $\phi'=\bigvee\Psi'$, $\phi\circ_\gamma\phi'=\bigvee\{\psi\circ_\gamma\psi'|(\psi, \psi')\in\Psi*_\gamma\Psi'\}$;\\
\hspace*{0.1in} $3$. When $\phi=\phi_0\land\bigwedge_{a\in\mathcal{B}}(K_a\phi_a\land L_a\Psi_a)$ and $\phi'=\phi_0'\land\bigwedge_{a\in\mathcal{B}'}(K_a\phi_a'\land L_a\Psi_a')$ \\
\hspace*{0.1in}\hspace{0.15in} where $\mathcal{B}, \mathcal{B'}\subseteq\mathcal{A}$, and $\phi\land\phi'$ is satisfiable wrt $\gamma$, $\phi\circ_\gamma\phi'=\phi\land\phi'$;\\
\hspace*{0.1in} $4$. When $\phi=\phi_0\land\bigwedge_{a\in\mathcal{B}}(K_a\phi_a\land L_a\Psi_a)$ and $\phi'=\phi_0'\land\bigwedge_{a\in\mathcal{B}'}(K_a\phi_a'\land L_a\Psi_a')$ \\
\hspace*{0.1in}\hspace{0.15in} where $\mathcal{B}, \mathcal{B'}\subseteq\mathcal{A}$, and $\phi\land\phi'$ is unsatisfiable wrt $\gamma$, \\
\hspace*{0.1in}\hspace{0.2in} $\phi\circ_\gamma\phi'\quad=\quad\phi_0\circ_\gamma\phi_0'$\hspace{3in}$(1)$\\
\hspace*{0.1in}\hspace{0.75in} $\land\quad\bigwedge_{a\in\mathcal{B}-\mathcal{B}'}(K_a\phi_a\land L_a\Psi_a)\land\bigwedge_{a\in\mathcal{B}'-\mathcal{B}}(K_a\phi_a'\land L_a\Psi_a')$\hspace{0.5in}$(2)$\\
\hspace*{0.1in}\hspace{0.75in} $\land\quad
   \bigwedge_{a\in\mathcal{B}\cap\mathcal{B}'}K_a[(\phi_a\circ_\gamma\phi_a')\lor
   \bigvee_{\psi_a'\in\Psi_a'}(\phi_a\circ_\gamma(\phi_a'\land\psi_a'))]$\hspace{0.5in}$(3)$\\
\hspace*{0.1in}\hspace{0.75in} $\land \quad \bigwedge_{a\in\mathcal{B}\cap\mathcal{B}'}L_a[\max{(\Psi_a'\cup\{\psi\circ_\gamma\psi'|(\psi,\psi')\in\Psi_a*_\gamma\{ \phi_K\}\})}]$\hspace{0.15in}$(4)$}\vspace{0.05in}\\
We use $\phi_K = (\phi_a\circ_\gamma\phi_a')\lor\bigvee_{\psi_a'\in\Psi_a'}(\phi_a\circ_\gamma(\phi_a'\land\psi_a'))$ to denote the result knowledge. Intuitively, Rule 1 is for propositional formulas, and Rule 2 and 3 are for the purpose of conjunction property. In Rule 4, (3) means that we revise the knowledge with new knowledge, and then to avoid contradiction, we also revise it with each $\phi_a'\land\psi_a'$. (4) denotes that we keep the old possibilities consistent with $\phi_K$, otherwise revise each one with $\phi_K$. Among the new possibilities, we remove the weaker one by maximizing. Next, before introducing the property of revision operator, we first define the notion of disjunctive-wise satisability.\vspace{0.05in}\\
\textbf{Definition 17.} \textit{Let $\phi$ be a ADNF, and $\gamma$ be a constraint. We say $\phi$ is disjunctive-wise satisfiable, in short d-satisfiable, wrt $\gamma$ if one of the following holds:\\
\hspace*{0.1in}$\bullet$ $\phi$ is a propositional term and $\phi\land\gamma$ is propositional satisfiable;\\
\hspace*{0.1in}$\bullet$ $\phi=\phi_0\land\bigwedge_{a\in\mathcal{A}}(K_a\phi_a\land L_a\Psi_a)$, $\phi$ is satisfiable wrt $\gamma$, and for all $a\in\mathcal{A}$, $\phi_a$ \\
\hspace*{0.1in}\hspace{0.1in} is d-satisfiable wrt $\gamma$ and for all $\psi_a\in\Psi_a$, $\psi_a$ is d-satisfiable wrt $\gamma$;\\
\hspace*{0.1in}$\bullet$ $\phi=\bigvee\Psi$, and for all $\psi\in\Psi, \psi$ is d-satisfiable wrt $\gamma$.}\vspace{0.05in}

The following shows some easy properties of our revision operator.\vspace{0.05in}\\
\textbf{Proposition 6.} \textit{Let $\phi$ and $\phi'$ be two ADNFs and $\gamma$ be a constraint. If $\phi\land\phi'$ is satisfiable, $\phi\circ_\gamma\phi'\Leftrightarrow_\gamma\phi\land\phi'$. Moreover, if both $\phi$ and $\phi'$ are d-satisfiable wrt $\gamma$, then $\phi\circ_\gamma\phi'\models_\gamma\phi'$ and $\phi\circ_\gamma\phi'$ is d-satisfiable wrt $\gamma$.}\vspace{0.05in}

We now move to update.\\
\textbf{Definition 18.} \textit{Let $\phi$ and $\phi'$ be two ADNFs and $\gamma$ be a constraint. The update of $\phi$ with $\phi'$ under $\gamma$, written $\phi\diamond_\gamma\phi'$, is defined recursively:\\
\hspace*{0.1in} $1$. When $\phi$ and $\phi'$ are propositional formulas, $\phi\diamond_\gamma\phi'=\phi\diamond_w(\phi'\land\gamma)$, where \\
\hspace*{0.1in}\hspace{0.17in} $\diamond_w$ is the Winslett's update operator\cite{winslett1988reasoning};\\
\hspace*{0.1in} $2$. When $\phi=\bigvee\Psi$, $\phi\diamond_\gamma\phi'=\bigvee_{\psi\in\Psi}(\psi\diamond_\gamma\phi')$;\\
\hspace*{0.1in} $3$. When $\phi'=\bigvee\Psi'$, $\phi\diamond_\gamma\phi'=\bigvee\{\psi\diamond_\gamma\psi'|(\psi, \psi')\in\{\phi\}*\Psi'\}$;\\
\hspace*{0.1in} $4$. When $\phi=\phi_0\land\bigwedge_{a\in\mathcal{B}}(K_a\phi_a\land L_a\Psi_a)$,  $\phi'=\phi_0'\land\bigwedge_{a\in\mathcal{B}'}(K_a\phi_a'\land L_a\Psi_a')$ where\\
\hspace*{0.1in}\hspace{0.2in} $\mathcal{B}, \mathcal{B}'\subseteq\mathcal{A}$, \\
\hspace*{0.1in}\hspace{0.2in} $\phi\diamond_\gamma\phi'\quad=\quad\phi_0\diamond_\gamma\phi_0'$\hspace{3in}$(1)$\\
\hspace*{0.1in}\hspace{0.75in} $\land\quad\bigwedge_{a\in\mathcal{B}-\mathcal{B}'}(K_a\phi_a\land L_a\Psi_a)\land\bigwedge_{a\in\mathcal{B}'-\mathcal{B}}(K_a\phi_a'\land L_a\Psi_a')$\hspace{0.5in}$(2)$\\
\hspace*{0.1in}\hspace{0.75in} $\land \quad
   \bigwedge_{a\in\mathcal{B}\cap\mathcal{B}'}K_a[(\phi_a\diamond_\gamma\phi_a')
   \lor\bigvee_{\psi_a'\in\Psi_a'}(\phi_a\diamond_\gamma(\phi_a'\land\psi_a'))]$\hspace{0.43in}$(3)$\\
\hspace*{0.1in}\hspace{0.75in} $\land \quad \bigwedge_{a\in\mathcal{B}\cap\mathcal{B}'}L_a[
   \max{(\Psi_a'\cup\{\psi_a\diamond_\gamma\phi_K|\psi_a\in\Psi_a\})}]$\hspace{0.81in}$(4)$}\vspace{0.05in}\\
Similar, $\phi_K=(\phi_a\diamond_\gamma\phi_a')\lor\bigvee_{\psi_a'\in\Psi_a'}(\phi_a\diamond_\gamma(\phi_a'\land\psi_a'))$ denotes the result knowledge. Intuitively, Rule 1 is for propositional formulas and Rule 2 for distribution property. Rule 3 denotes that we concern the consistent formulas whenever possible and Rule 4 is similar to that in revision operator. \\
\textbf{Proposition 7.} \textit{Let $\phi_1$, $\phi_2$, $\phi$ and $\phi'$ be the ADNFs and $\gamma$ be a constraint. Then $(\phi_1\lor\phi_2)\diamond_\gamma\phi'\Leftrightarrow_\gamma(\phi_1\diamond_\gamma\phi'\lor\phi_2\diamond_\gamma\phi')$. Moreover, if both $\phi$ and $\phi'$ are d-satisfiable wrt $\gamma$, then $\phi\diamond_\gamma\phi'\models_\gamma\phi'$ and $\phi\diamond_\gamma\phi'$ is d-satisfiable wrt $\gamma$.}

\section{Planning}
Currently, heuristic search has been widely used for planning. Recall that our planner searches for solution through the space of KBs, thus we also apply heuristic search for acceleration. In this section, we will introduce the heuristic function, the main search algorithm, and finally two heuristic pruning strategies.
\subsection{Heuristic Function}
\textbf{Definition 19.} \textit{Let $\phi$ and $\phi'$ be two ADNFs. The distance from $\phi$ to $\phi'$, written $dist(\phi, \phi')$, is defined recursively:\\
\hspace*{0.1in} $1$. When $\phi$ and $\phi'$ are propositional terms, $dist(\phi, \phi')$ is the number of \\\hspace*{0.3in} literals of $\phi'$ which are not entailed by $\phi$;\\
\hspace*{0.1in} $2$. When $\phi=\bigvee\Psi, \phi^\prime=\bigvee\Psi^\prime$, $dist(\phi, \phi')=\min (\{dist(\psi, \psi^\prime)$ $|$ $\psi\in\Psi, \psi^\prime\in\Psi^\prime\})$;\\
\hspace*{0.1in} $3$. When $\phi=\phi_0\land\bigwedge_{a\in\mathcal{B}}(K_a\phi_a\land L_a\Psi_a)$, $\phi'=\phi_0'\land\bigwedge_{a\in\mathcal{B}'}(K_a\phi_a'\land L_a\Psi_a')$ ,\\
\hspace*{0.1in}\hspace{0.2in} $dist(\phi, \phi')$\quad$=$\quad$dist(\phi_0, \phi_0')$\hspace{2.6in}$(1)$\\
\hspace*{0.1in}\hspace{0.838in}\quad$+$\quad$\sum_{a\in\mathcal{B}'-\mathcal{B}}dist(\top, \phi_a')
   + \sum_{a\in\mathcal{B}'-\mathcal{B}}\sum_{\psi_a'\in\Psi_a'}dist(\top, \psi_a')$\hspace{0.13in}$(2)$\\
\hspace*{0.1in}\hspace{0.838in}\quad$+$\quad$\sum_{a\in\mathcal{B}'\cap\mathcal{B}}dist(\phi_a, \phi_a')$\hspace{2.03in}$(3)$\\
\hspace*{0.1in}\hspace{0.838in}\quad$+$\quad$\sum_{a\in\mathcal{B}'\cap\mathcal{B}}\sum_{\psi_a'\in\Psi_a'}
\min(\{dist(\psi_a,\psi_a')|\psi_a\in\Psi_a\})$\hspace{0.51in}$(4)$}\vspace{0.05in}\\
Note that we concern the distance from $\phi$ to $\phi'$ but not the other direction. Intuitively, in Rule 3, for each $a\in\mathcal{B}'$, we add up the distance between $\phi_a$ ($\top$ if $a\not\in\mathcal{B}$) and $\phi_a'$, and for each $\psi_a'\in\Psi_a'$, add up the minimal distance between each $\psi_a\in\Psi_a$ ($\top$ if $a\not\in\mathcal{B}$) and $\psi_a'$.\vspace{0.05in}\\
\textbf{Definition 20.} \textit{Let $\phi$ be an ADNF and $\mathcal{G}$ be the goal. The heuristic value of $\phi$, written $h(\phi)$, is defined as: $h(\phi)=dist(\phi, \mathcal{G})$.}

\subsection{AO* with Cycle Checking}
AO* and LAO*\cite{Hansen2001LAO} are two heuristic search algorithms for AND/OR graph with the difference that LAO* can handle graphs with loops and find a solution with loops while AO* cannot. Recall that the solution for MEP problem is an action tree without loops, so we adapt AO* as our main search algorithm which is much more efficient. However, there may be loops throughout the search space keeping AO* from halting. In this section, we will introduce the AO* with Cycle Checking algorithm for our planner. Because we represent KBs as ADNFs, we apply the satisfiability algorithm for reasoning, strong equivalence algorithm for cycle checking, revision and update algorithms for progression wrt sensing and deterministic actions. We begin with some notions used in our algorithm:\\
\hspace*{0.1in}$\bullet$ We define a policy $\pi: $ KBs $\rightarrow \mathcal{S}\cup\mathcal{D}\cup\{Ter., Undef.\}$ as a mapping from\\
\hspace*{0.1in}\hspace{0.1in}  KBs to actions, where Ter. denotes terminate and Undef. denotes undefined;\\
\hspace*{0.1in}$\bullet$ $negEntail(s, \mathcal{G})$ returns true iff $s\land\lnot\mathcal{G}$ is unsatisfiable wrt $\gamma$;\\
\hspace*{0.1in}$\bullet$ $HeuristicHelper(s)$ returns $h(s)$;\\
\hspace*{0.1in}$\bullet$ $ExtractPolicy(\mathcal{I)}$ extracts new policy $\pi'$. Note that our planner will per-\\
\hspace*{0.1in}\hspace{0.1in} form Cycle Checking here to make sure that the policy contains no loops.\\
\centerline{
        $\pi'(s) := \begin{cases}
            Ter. &negEntail(s, \mathcal{G}) \text{ returns true}\\
            Undef. &s \text{ is unexplored}\\
            \arg\min\limits_{a\in A} Cost(a) &\text{otherwise}
        \end{cases}
        $}\\
\hspace*{0.1in}\hspace{0.1in} $A=\{a'|a'\in\mathcal{S}\cup\mathcal{D}, s\models_\gamma pre(a')\}$, and if $a\in\mathcal{D}, Cost(a)=1+f(prog(s,a)) $;\\
\hspace*{0.1in}\hspace{0.1in} else $Cost(a)=2+0.5*f(\phi^+)+0.5*f(\phi^-)$, where $prog(s, a)=\langle \phi^+,\phi^-\rangle$.\\
\hspace*{0.1in}$\bullet$ $ExtractSol(\pi)$ extracts the solution tree from policy $\pi$;\\
\hspace*{0.1in}$\bullet$ $isSolved(s)$ returns true if one of the following holds:(1) $negEntail(s, \mathcal{G})$ re-\\
\hspace*{0.1in}\hspace{0.1in}turns true;(2) $\pi(s)\in\mathcal{D}$ and $isSolved(prog(s,\pi(s)))$ returns true;(3) $\pi(s)\in\mathcal{S},$\\
\hspace*{0.1in}\hspace{0.1in}$isSolved(\phi^+)$ and $isSolved(\phi^-)$ return true where $prog(s,\pi(s)) = \langle\phi^+,\phi^-\rangle$.\\
Algorithm \ref{alg1} shows the main algorithm for our planner.
\begin{algorithm}[!t]
\caption{CAO*}
\label{alg1}
\begin{algorithmic}
\REQUIRE Initial state $\mathcal{I}$, goal $\mathcal{G}$, constraint $\gamma$, sets of sensing and deterministic actions $\mathcal{S}$ and $\mathcal{D}$
\ENSURE Solution action tree $T$
\RETURN Initialize the policy $\pi$ contains only $\pi(\mathcal{I})=Undef.$
\IF {$negEntail(\mathcal{I}, \mathcal{G})$ returns true} \STATE \textbf{return} $T$ \ENDIF
\REPEAT
\STATE 1. Choose a state $s$ in $\pi$ s.t $\pi(s)=Undef.$
\STATE 2. Explore $s$, and assign state cost for every new state $s'$:\\
        \centerline{$f(s')=
          \begin{cases}
            0 &negEntail(s', \mathcal{G})$ returns true $\\
            HeuristicHelper(s') &\text{otherwise}
          \end{cases}
          $}
\STATE 3. Add all the new states to $\pi$, if $negEntail(s', \mathcal{G})$ returns true, then $\pi(s')=Ter.$; else $\pi(s')=Undef.$ And assign a random action for $\pi(s)$.
\STATE 4. Apply backtracking algorithm to update state cost in $\pi$:\\
        $f(s)=
          \begin{cases}
            f(s) &\pi(s)\in\{Undef., Ter.\}\\
            1+f(prog(s,\pi(s))) &\pi(s)\in\mathcal{D}\\
            2+0.5*f(\phi^+)+0.5*f(\phi^-) &\pi(s)\in\mathcal{S}, prog(s,\pi(s))=\langle \phi^+,\phi^-\rangle
          \end{cases}
          $
\STATE 5. Extract new policy, $\pi'\leftarrow ExtractPolicy(\mathcal{I})$
\STATE 6. If $\pi$ equals $\pi'$, do nothing; Else $\pi\leftarrow \pi'$, goto \textbf{Step 4}.
\UNTIL $isSolve(\mathcal{I})$ returns true
\STATE $T\leftarrow ExtractSol(\pi)$
\STATE \textbf{return} $T$

\end{algorithmic}
\end{algorithm}
\subsection{Heuristic Pruning Strategy}
In this section, we will introduce two heuristic pruning strategies:

\textbf{Deadend Propagation}: Deadend propagation aims to handle the dead end during searching. We say a state is a deadend if $isDeadend(s)$ returns true, where $isDeadend(s)$ returns true if one of the following holds: (1) $s\not\models_\gamma\mathcal{G}$ and $\forall a\in\mathcal{S}\cup\mathcal{D}, s\not\models_\gamma pre(a)$; (2) $s\not\models_\gamma\mathcal{G}$, $\forall a\in\mathcal{D}, isDeadend(prog(s,a))$ returns true and $\forall a\in\mathcal{S}$, $isDeadend(s^+)$ and $isDeadend(s^-)$ return true, where $prog(s,a)=\langle s^+, s^- \rangle$. When we encounter a deadend $s$, we will label it by assigning a big value as its state cost and apply $deadendPropagation$ function recursively:\\
\hspace*{0.05in}$-$ If there exist an action $a\in\mathcal{D}$ and a state $s'$ s.t $prog(s',a)\leftrightarrow_\gamma s$, perform\\
\hspace*{0.05in}\quad $deadendPropagation(s')$ recursively.\\
\hspace*{0.05in}$-$ If there exist action $a\in\mathcal{S}$ and a state $s'$ s.t $s^+ \leftrightarrow_\gamma s$ or $s^- \leftrightarrow_\gamma s$ where\\
\hspace*{0.05in}\quad $prog(s',a) = \langle s^+, s^- \rangle$, perform $deadendPropagation(s')$ recursively.

\textbf{Common Sub-Formula}: This strategy aims to enhance our heuristic function by distinguishing the formulas inconsistent with the common part of the initial state and the goal.  Let $\phi$ and $\phi'$ be two ADNFs. The Common Sub-Formula of $\phi$ and $\phi'$, written $csf(\phi, \phi')$, is an ADNF defined as follows:\\
      $\bullet$ When $\phi$ and $\phi'$ are propositional terms, $csf(\phi,\phi')$ is the conjunction of the \\ \hspace*{0.1in}common literals of $\phi$ and $\phi'$;\\
      $\bullet$ When $\phi=\bigvee\{\psi_1,\psi_2,...,\psi_n\}$, $csf(\phi,\phi')=csf(\psi_1, csf(..., csf(\psi_n, \phi')))$;\\
      $\bullet$ When $\phi'=\bigvee\{\psi_1',\psi_2',...,\psi_n'\}$, $csf(\phi,\phi')=csf(csf(...csf(\phi,\psi_1')..., \psi_{n-1}'), \psi_n')$;\\
      $\bullet$ When $\phi=\phi_0\land\bigwedge_{a\in\mathcal{B}}(K_a\phi_a\land L_a\Psi_a)$ and $\phi'=\phi_0'\land\bigwedge_{a\in\mathcal{B}'}(K_a\phi_a'\land L_a\Psi_a')$ \\ \hspace*{0.1in}where $\mathcal{B},\mathcal{B}'\subseteq\mathcal{A}$,  $csf(\phi,\phi')=csf(\phi_0,\phi_0')\land\bigwedge_{a\in\mathcal{B}\cap\mathcal{B}'}[K_a(csf(\phi_a,\phi_a'))\land $\\ \hspace*{0.1in}$L_a(\{csf(\psi_a, \psi_a')|\psi_a\in\Psi_a, \psi_a'\in\Psi_a'\})]$.

      Our planner will first calculate the common sub-formula of the initial state and the goal, that is $csf(\mathcal{I}, \mathcal{G})$, and for every new formula $\phi$ generated during searching, we will increase its heuristic value if $\phi\land csf(\mathcal{I}, \mathcal{G})$ is not satisfiable wrt $\gamma$. The intuition for this pruning strategy is that $csf(\mathcal{I}, \mathcal{G})$ denotes the part in $\mathcal{I}$ consistent with $\mathcal{G}$, therefore we think that a new formula inconsistent with $csf(\mathcal{I}, \mathcal{G})$ may have higher probability of misleading the search.

\section{Implementation and Experiments}
Based on the theoretic work, we have implemented a Multi-Agent Epistemic Planner called MEPL. MEPL takes as input a file in EPDDL, an extension of PDDL \cite{mcdermott1998pddl} for describing MEP problems, and outputs a solution tree if it exists and the search statistics. We evaluate MEPL with all the domains from \cite{Liu2017A}, which include Hexa Game, Collaboration-and-Communication(CC), Gossip, Grapevine, Selective-Communication(SC) and Assembly-Line(AL). Besides, inspired by \cite{kominis2015beliefs}, we make up a new domain Simple Muddy Children(SMC) by removing the public announcement action. The domain is as follows:

There are $n$ children and at least one and at most $n-1$ children are muddy in their heads. A child A can sense whether another child B is muddy and can also ask whether B knows if B is muddy. Initially there is a child who doesn't know whether he is muddy and the goal is for him to know if he is muddy.

Our experiments were run on a Linux machine with 2.50GHz CPU and 4GB RAM, and Table \ref{t1} shows the experimental statistics. Note that the first column in the table is the name of the domain, and the 2nd-3th columns indicate the number of agents and the modal depth, respectively. In the last two columns, $A-B(X/Y/Z)$ denotes $A$ seconds of total time, $B$ seconds of search time, $X$ is the solution tree depth, $Y$ nodes of solution tree, and $Z$ nodes explored during search. $N/A$ denotes unsolvable  within the allotted time.
%\begin{table} [!htbp]\label{t1}
%\centering
\begin{center}
\begin{longtable}{|c|c|c|c|c|}
\hline
Problem & $|\mathcal{A}|$ & $d$ & MEPK & MEPL\\
\hline
\multirow{3} {*} {Hexa Game} & 3&1&0.00-0.00(1/3/1)&\textbf{0.00-0.00(1/3/1)} \\
& 4&1&0.02-0.02(3/11/6)&\textbf{0.02-0.02(4/11/5)}\\
& 5&1&28.08-24.64(6/47/185)&\textbf{1.14-1.13(7/47/23)}\\
& 6&1&N/A&\textbf{173.31-173.20(11/239/119)}\\
\hline
CC(2,4)&2&1&0.14-0.13(3/4/4)&\textbf{0.09-0.08(3/4/3)} \\
CC(3,4)&2&1&1.87-1.85(3/4/4)&\textbf{1.01-1.00(3/4/3)} \\
CC(4,4)&2&1&81.31-81.24(3/4/4)&\textbf{34.57-34.55(3/4/3)} \\
*CC(2,3)$^1$&2&1&\textbf{3.49-3.48(4/12/35)}&3.76-3.75(4/9/16) \\
*CC(2,3)$^2$&2&1&11.70-11.69(5/16/312)&\textbf{1.31-1.30(5/11/37)} \\
*CC(2,4)&2&1&8.68-8.67(6/18/300)&\textbf{0.78-0.78(7/21/28)} \\
*CC(3,3)&3&1&10.12-10.09(3/15/50)&\textbf{2.86-2.85(5/13/23)} \\
*CC(3,4)&3&1&N/A&\textbf{32.76-32.75(9/21/29)} \\
\hline
\multirow{3} {*} {Gossip}
&3&2&0.04-0.03(3/4/5)&\textbf{0.02-0.01(3/4/3)} \\
&4&2&4.98-4.35(4/5/47)&\textbf{1.20-1.18(4/5/13)} \\
&5&2&17.46-11.60(4/5/47)&\textbf{4.43-4.33(4/5/13)} \\
\hline
Grapevine(2)&3&2&0.02-0.01(2/3/7)&\textbf{0.01-0.01(2/3/4)} \\
Grapevine(2)&4&1&0.09-0.05(2/3/8)&\textbf{0.06-0.05(2/3/5)} \\
Grapevine(2)&4&2&0.11-0.07(2/3/8)&\textbf{0.06-0.04(2/3/4)} \\
Grapevine(2)&4&3&0.17-0.11(2/3/8)&\textbf{0.08-0.05(2/3/4)} \\
Grapevine(2)&4&4&0.30-0.20(2/3/8)&\textbf{0.10-0.07(2/3/4)} \\
\hline
Grapevine(3)&4&1&1.10-0.71(2/3/9)&\textbf{0.20-0.13(2/3/5)} \\
Grapevine(3)$^1$&5&1&N/A&\textbf{7.45-7.31(2/3/20)} \\
Grapevine(3)$^2$&5&1&N/A&\textbf{32.31-32.17(3/4/46)} \\
\hline
SC(4)&3&1&\textbf{0.04-0.03(5/10/23)}&0.06-0.06(5/10/20) \\
SC(4)&7&1&13.72-0.05(5/10/23)&\textbf{0.28-0.28(5/10/20)} \\
SC(4)$^1$&8&1&110.48-0.10(5/10/39)&\textbf{0.60-0.59(5/10/26)} \\
SC(4)$^2$&8&1&118.17-0.03(3/6/8)&\textbf{0.06-0.04(3/6/4)} \\
SC(4)&3&3&0.04-0.03(5/10/23)&\textbf{0.04-0.04(5/10/14)} \\
SC(4)&3&4&0.07-0.05(5/10/23)&\textbf{0.05-0.05(5/10/14)} \\
SC(8)&3&1&\textbf{0.21-0.14(10/19/41)}&0.36-0.35(10/19/30) \\
\hline
\multirow{5} {*} {AL}
&2&2&0.02-0.01(5/12/25)&\textbf{0.02-0.02(5/12/16)} \\
&2&3&0.03-0.03(5/12/25)&\textbf{0.03-0.03(5/12/16)} \\
&2&4&0.03-0.03(5/12/25)&\textbf{0.03-0.03(5/12/16)} \\
&2&5&0.05-0.04(5/12/25)&\textbf{0.04-0.04(5/12/16)} \\
&2&7&0.13-0.12(5/12/25)&\textbf{0.07-0.07(5/12/16)} \\
\hline
SMC(3)&3&1&0.10-0.10(3/11/24)&\textbf{0.01-0.01(3/11/5)} \\
SMC(4)&4&1&406.95-406.94(5/27/706)&\textbf{0.42-0.40(5/27/13)} \\
SMC(5)&5&1&N/A&\textbf{1.59-1.55(5/27/13)} \\
SMC(6)&6&1&N/A&\textbf{6.57-6.37(5/27/13)} \\
\hline
\caption{\label{t1}Experimental Results}
\end{longtable}
\end{center}
The experimental results show that our planner outperforms MEPK in three aspects. Firstly, our planner performs much better than MEPK for most instances, especially when the size of the instances grows.
The reason is that ADNFs are more space efficient, and our reasoning and progression algorithms are more efficient. Secondly, for all instances, the number of nodes explored by our planner is less than that by
MEPK, which shows the viability of our heuristic function and pruning strategies. Finally, the preprocessing of our planner is much faster than that of MEPK: our planner can complete the preprocessing within $1s$ while MEPK may take more than 100s in some domains like SC. Thus it's possible for our planner to handle larger instances, i.e., our planner scales better.

\section{Conclusions}
In this paper, we have proposed two improvements for the multi-agent epistemic planner MEPK, which is based on higher-order belief change and forward state space search. Firstly,
we exploited alternating disjunctive normal form (ADNF) for multi-agent KD45, which is more space efficient than the normal form used by MEPK and also saves time in compilation, and proposed efficient reasoning, revision, and update algorithms for it. Secondly, as the planning algorithm, we applied heuristic research AO* with cycle checking and two heuristic pruning strategies.
We implemented a multi-agent epistemic planner MEPL, which outperformed MEPK in most planning instances, and solved a number of instances that MEPK cannot solve. Like MEPK, MEPL can handle propositional common knowledge, called constraints.
Nonetheless, MEPL does not handle complex constraints well. In the future, we are interested in overcoming this limitation and further dealing with general common knowledge.


\bibliographystyle{splncs}
\bibliography{paper}
\end{document}
